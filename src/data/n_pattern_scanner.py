#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Nå­—å›æ’¤æƒæå¼•æ“
æ•´åˆ ZigZag è½‰æŠ˜é»åµæ¸¬ã€æŠ€è¡“æŒ‡æ¨™è¨ˆç®—ã€ABC å½¢æ…‹è­˜åˆ¥å’Œè©•åˆ†ç³»çµ±
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import sqlite3
from typing import List, Dict, Optional, Tuple
import logging
from pathlib import Path

try:
    from .zigzag import ZigZagDetector
    from .indicators import NPatternIndicators
except ImportError:
    # ç•¶ç›´æ¥é‹è¡Œæ­¤æª”æ¡ˆæ™‚çš„fallback
    import sys
    import os
    sys.path.insert(0, os.path.dirname(__file__))
    from zigzag import ZigZagDetector
    from indicators import NPatternIndicators

logger = logging.getLogger(__name__)

class NPatternScanner:
    """Nå­—å›æ’¤æƒæå™¨ä¸»é¡"""
    
    def __init__(self, 
                 lookback_bars: int = 60,
                 min_change_pct: float = 0.08,
                 retr_min: float = 0.30,
                 retr_max: float = 0.70,
                 c_tolerance: float = 0.01):
        """
        åˆå§‹åŒ–æƒæå™¨
        
        Args:
            lookback_bars: å›çœ‹Kç·šæ ¹æ•¸ (é è¨­60æ ¹)
            min_change_pct: ZigZagæœ€å°è®ŠåŒ–ç™¾åˆ†æ¯” (é è¨­8%)
            retr_min: æœ€å°å›æ’¤æ¯”ä¾‹ (é è¨­30%)  
            retr_max: æœ€å¤§å›æ’¤æ¯”ä¾‹ (é è¨­70%)
            c_tolerance: Cé»ç›¸å°Aé»å®¹å·® (é è¨­1%)
        """
        self.lookback_bars = lookback_bars
        self.min_change_pct = min_change_pct
        self.retr_min = retr_min
        self.retr_max = retr_max
        self.c_tolerance = c_tolerance
        
        self.zigzag = ZigZagDetector(min_change_pct=min_change_pct)
        
    def scan_single_stock(self, stock_data: pd.DataFrame, stock_id: str, stock_name: str) -> Optional[Dict]:
        """
        æƒæå–®ä¸€è‚¡ç¥¨çš„Nå­—å›æ’¤å½¢æ…‹
        
        Args:
            stock_data: è‚¡ç¥¨OHLCè³‡æ–™ DataFrame
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            stock_name: è‚¡ç¥¨åç¨±
            
        Returns:
            æƒæçµæœ dict æˆ– None
        """
        try:
            # ç¢ºä¿æœ‰è¶³å¤ çš„è³‡æ–™
            if len(stock_data) < self.lookback_bars:
                logger.debug(f"{stock_id} è³‡æ–™ä¸è¶³: {len(stock_data)} < {self.lookback_bars}")
                return None
            
            # åªå–æœ€è¿‘çš„ lookback_bars æ ¹Kç·š
            recent_data = stock_data.tail(self.lookback_bars).copy()
            recent_data = recent_data.reset_index(drop=True)
            
            # 1. ZigZag è½‰æŠ˜é»åµæ¸¬
            pivots = self.zigzag.detect_zigzag_points(recent_data)
            if len(pivots) < 3:
                logger.debug(f"{stock_id} ZigZagè½‰æŠ˜é»ä¸è¶³: {len(pivots)}")
                return None
            
            # 2. å°‹æ‰¾æœ€å¾Œä¸€çµ„ABCå½¢æ…‹
            abc_pattern = self.zigzag.find_last_abc_pattern(pivots)
            if not abc_pattern:
                logger.debug(f"{stock_id} æœªæ‰¾åˆ°ç¬¦åˆçš„ABCå½¢æ…‹")
                return None
            
            A, B, C = abc_pattern
            
            # 3. é¡å¤–çš„å›æ’¤æ¯”ä¾‹é©—è­‰
            retr_pct = (B['price'] - C['price']) / (B['price'] - A['price'])
            if not (self.retr_min <= retr_pct <= self.retr_max):
                logger.debug(f"{stock_id} å›æ’¤æ¯”ä¾‹ä¸ç¬¦: {retr_pct:.3f}")
                return None
            
            # 4. Cé»ä¸ç ´Aé»é©—è­‰
            if C['price'] <= A['price'] * (1 - self.c_tolerance):
                logger.debug(f"{stock_id} Cé»ç ´Aé»: C={C['price']:.2f}, A={A['price']:.2f}")
                return None
            
            # 5. è¨ˆç®—æŠ€è¡“æŒ‡æ¨™
            indicators = NPatternIndicators(recent_data)
            
            # 6. æª¢æŸ¥è§¸ç™¼æ¢ä»¶
            triggers = indicators.check_trigger_conditions()
            if not triggers['any_triggered']:
                logger.debug(f"{stock_id} æœªè§¸ç™¼ä»»ä½•æ¢ä»¶")
                return None
            
            # 7. è¨ˆç®—è©•åˆ†
            score_result = indicators.calculate_pattern_score(A, B, C)
            latest_values = indicators.get_latest_values()
            
            # 8. æº–å‚™è¿”å›çµæœ
            result = {
                'stock_id': stock_id,
                'stock_name': stock_name,
                'scan_date': datetime.now().strftime('%Y-%m-%d'),
                
                # ABCè½‰æŠ˜é»
                'A_date': A['date'],
                'A_price': A['price'],
                'A_index': A['index'],
                'B_date': B['date'],
                'B_price': B['price'], 
                'B_index': B['index'],
                'C_date': C['date'],
                'C_price': C['price'],
                'C_index': C['index'],
                
                # å½¢æ…‹æŒ‡æ¨™
                'rise_pct': (B['price'] - A['price']) / A['price'],
                'retracement_pct': retr_pct,
                'bars_ab': B['index'] - A['index'],
                'bars_bc': C['index'] - B['index'],
                'bars_c_to_today': len(recent_data) - C['index'] - 1,
                
                # ç•¶å‰åƒ¹æ ¼èˆ‡æŒ‡æ¨™
                'current_price': latest_values['close'],
                'ema5': latest_values['ema5'],
                'ema20': latest_values['ema20'],
                'rsi14': latest_values['rsi14'],
                'volume_ratio': latest_values['volume_ratio'],
                
                # è§¸ç™¼æ¢ä»¶
                'trigger_break_high': triggers['condition1_break_high'],
                'trigger_volume_ema': triggers['condition2_volume_ema'],
                'trigger_rsi_strong': triggers['condition3_rsi_strong'],
                'trigger_count': triggers['trigger_count'],
                
                # è©•åˆ†
                'total_score': score_result['total_score'],
                'score_breakdown': score_result['breakdown'],
                'score_metrics': score_result['metrics']
            }
            
            logger.info(f"âœ… {stock_id} ({stock_name}): Score={result['total_score']}, "
                       f"Rise={result['rise_pct']:.1%}, Retr={result['retracement_pct']:.1%}")
            
            return result
            
        except Exception as e:
            logger.error(f"æƒæ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            return None
    
    def get_stock_data(self, stock_id: str, db_path: str) -> Optional[pd.DataFrame]:
        """
        å¾è³‡æ–™åº«ç²å–è‚¡ç¥¨æ­·å²è³‡æ–™
        
        Args:
            stock_id: è‚¡ç¥¨ä»£ç¢¼
            db_path: è³‡æ–™åº«è·¯å¾‘
            
        Returns:
            è‚¡ç¥¨è³‡æ–™ DataFrame æˆ– None
        """
        try:
            conn = sqlite3.connect(db_path)
            
            # å…ˆæª¢æŸ¥æ˜¯å¦æœ‰è©²è‚¡ç¥¨çš„è³‡æ–™è¡¨
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (f"stock_{stock_id}",))
            if not cursor.fetchone():
                logger.debug(f"è‚¡ç¥¨ {stock_id} ç„¡è³‡æ–™è¡¨")
                return None
            
            # ç²å–æœ€è¿‘çš„è³‡æ–™
            query = f"""
            SELECT date, open, high, low, close, volume
            FROM stock_{stock_id}
            ORDER BY date DESC
            LIMIT {self.lookback_bars + 10}
            """
            
            df = pd.read_sql_query(query, conn)
            conn.close()
            
            if len(df) < self.lookback_bars:
                return None
                
            # æŒ‰æ—¥æœŸæ­£åºæ’åˆ—
            df = df.sort_values('date').reset_index(drop=True)
            df['date'] = pd.to_datetime(df['date'])
            
            return df
            
        except Exception as e:
            logger.error(f"ç²å– {stock_id} è³‡æ–™æ™‚éŒ¯èª¤: {e}")
            return None
    
    def scan_stock_universe(self, universe_db_path: str, price_db_path: str = None) -> List[Dict]:
        """
        æƒææ•´å€‹è‚¡ç¥¨å®‡å®™
        
        Args:
            universe_db_path: è‚¡ç¥¨å®‡å®™è³‡æ–™åº«è·¯å¾‘
            price_db_path: åƒ¹æ ¼è³‡æ–™åº«è·¯å¾‘ (å¦‚æœç‚ºNoneå‰‡ä½¿ç”¨universe_db_path)
            
        Returns:
            æƒæçµæœåˆ—è¡¨
        """
        if price_db_path is None:
            price_db_path = universe_db_path
            
        results = []
        
        try:
            # ç²å–è‚¡ç¥¨æ¸…å–®
            conn = sqlite3.connect(universe_db_path)
            stock_list = pd.read_sql_query(
                "SELECT stock_id, name FROM stock_universe WHERE status='active' ORDER BY stock_id", 
                conn
            )
            conn.close()
            
            total_stocks = len(stock_list)
            logger.info(f"é–‹å§‹æƒæ {total_stocks} æª”è‚¡ç¥¨...")
            
            scanned_count = 0
            found_count = 0
            
            for idx, row in stock_list.iterrows():
                stock_id = row['stock_id']
                stock_name = row['name']
                
                # ç²å–è‚¡ç¥¨è³‡æ–™
                stock_data = self.get_stock_data(stock_id, price_db_path)
                if stock_data is None:
                    continue
                
                # æƒæå½¢æ…‹
                result = self.scan_single_stock(stock_data, stock_id, stock_name)
                if result:
                    results.append(result)
                    found_count += 1
                
                scanned_count += 1
                
                # é€²åº¦å ±å‘Š
                if scanned_count % 100 == 0:
                    logger.info(f"å·²æƒæ: {scanned_count}/{total_stocks}, æ‰¾åˆ°: {found_count}")
            
            logger.info(f"æƒæå®Œæˆ! ç¸½è¨ˆæƒæ: {scanned_count}, æ‰¾åˆ°Nå­—å½¢æ…‹: {found_count}")
            
        except Exception as e:
            logger.error(f"æƒæè‚¡ç¥¨å®‡å®™æ™‚éŒ¯èª¤: {e}")
        
        # æŒ‰è©•åˆ†æ’åº
        results.sort(key=lambda x: x['total_score'], reverse=True)
        return results
    
    def save_scan_results(self, results: List[Dict], output_path: str):
        """
        ä¿å­˜æƒæçµæœ
        
        Args:
            results: æƒæçµæœåˆ—è¡¨
            output_path: è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
        """
        if not results:
            logger.warning("ç„¡æƒæçµæœå¯ä¿å­˜")
            return
        
        # è½‰æ›ç‚ºDataFrame
        df = pd.DataFrame(results)
        
        # é‡æ–°æ’åˆ—æ¬„ä½é †åº
        columns = [
            'stock_id', 'stock_name', 'total_score', 'scan_date',
            'current_price', 'rise_pct', 'retracement_pct',
            'A_date', 'A_price', 'B_date', 'B_price', 'C_date', 'C_price',
            'bars_ab', 'bars_bc', 'bars_c_to_today',
            'ema5', 'ema20', 'rsi14', 'volume_ratio',
            'trigger_break_high', 'trigger_volume_ema', 'trigger_rsi_strong', 'trigger_count'
        ]
        
        # ç¢ºä¿æ‰€æœ‰æ¬„ä½éƒ½å­˜åœ¨
        available_columns = [col for col in columns if col in df.columns]
        df_output = df[available_columns]
        
        # æ ¼å¼åŒ–ç™¾åˆ†æ¯”
        if 'rise_pct' in df_output.columns:
            df_output['rise_pct'] = df_output['rise_pct'].map(lambda x: f"{x:.2%}")
        if 'retracement_pct' in df_output.columns:
            df_output['retracement_pct'] = df_output['retracement_pct'].map(lambda x: f"{x:.2%}")
        
        # ä¿å­˜CSV
        csv_path = output_path.replace('.xlsx', '.csv')
        df_output.to_csv(csv_path, index=False, encoding='utf-8')
        logger.info(f"æƒæçµæœå·²ä¿å­˜è‡³: {csv_path}")
        
        # ä¿å­˜Excel (å¦‚æœå¯ä»¥)
        try:
            df_output.to_excel(output_path, index=False)
            logger.info(f"æƒæçµæœå·²ä¿å­˜è‡³: {output_path}")
        except ImportError:
            logger.warning("æœªå®‰è£openpyxlï¼Œè·³éExcelè¼¸å‡º")

def test_scanner():
    """æ¸¬è©¦Nå­—å›æ’¤æƒæå™¨"""
    # å‰µå»ºæ¸¬è©¦è³‡æ–™
    scanner = NPatternScanner(lookback_bars=60)
    
    # ç”Ÿæˆå›ºå®š60å¤©çš„æ¸¬è©¦è³‡æ–™
    np.random.seed(42)  # å›ºå®šéš¨æ©Ÿç¨®å­
    dates = pd.date_range('2024-01-01', periods=60, freq='D')
    
    # ç°¡åŒ–çš„Nå­—å½¢æ…‹ç”Ÿæˆ
    prices = []
    
    # å‰20å¤©ï¼šåŸºç¤åƒ¹æ ¼100é™„è¿‘
    for i in range(20):
        prices.append(100 + np.random.uniform(-2, 2))
    
    # 21-35å¤©ï¼šä¸Šæ¼²æ®µ (Aåˆ°B)
    for i in range(15):
        prices.append(prices[-1] + np.random.uniform(0.5, 1.2))
    
    # 36-45å¤©ï¼šå›æ’¤æ®µ (Båˆ°C)
    peak_price = max(prices[-15:])
    for i in range(10):
        retr = peak_price * 0.06  # æ¯å¤©å›æ’¤6%çš„å³°å€¼
        prices.append(prices[-1] - retr + np.random.uniform(-0.5, 0.5))
    
    # 46-60å¤©ï¼šæ•´ç†æ®µ
    for i in range(15):
        prices.append(prices[-1] + np.random.uniform(-1, 1))
    
    # å‰µå»ºOHLCè³‡æ–™
    df = pd.DataFrame({
        'date': dates,
        'open': [max(1, p + np.random.uniform(-0.5, 0.5)) for p in prices],
        'high': [max(1, p + abs(np.random.uniform(0, 1))) for p in prices],
        'low': [max(1, p - abs(np.random.uniform(0, 1))) for p in prices],
        'close': prices,
        'volume': [int(np.random.uniform(1000000, 5000000)) for _ in range(60)]
    })
    
    # æ¸¬è©¦æƒæ
    result = scanner.scan_single_stock(df, '9999', 'æ¸¬è©¦è‚¡ç¥¨')
    
    if result:
        print("ğŸ¯ æ‰¾åˆ°Nå­—å›æ’¤å½¢æ…‹!")
        print(f"è‚¡ç¥¨: {result['stock_id']} ({result['stock_name']})")
        print(f"è©•åˆ†: {result['total_score']}")
        print(f"ä¸Šæ¼²å¹…åº¦: {result['rise_pct']:.1%}")
        print(f"å›æ’¤æ¯”ä¾‹: {result['retracement_pct']:.1%}")
        print(f"è§¸ç™¼æ¢ä»¶æ•¸: {result['trigger_count']}")
        print(f"A: {result['A_date']} = {result['A_price']:.2f}")
        print(f"B: {result['B_date']} = {result['B_price']:.2f}")
        print(f"C: {result['C_date']} = {result['C_price']:.2f}")
    else:
        print("æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„Nå­—å½¢æ…‹")

if __name__ == "__main__":
    test_scanner()