#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨ä¾‹å¤–è¦å‰‡çš„å®Œæ•´Nå­—æƒæç³»çµ±
ä¸»è¦ç¯©é¸ï¼šABâ‰¥3å¤©ï¼ŒBCâ‰¥3å¤©ï¼Œæ³¢æ®µâ‰¥6%
ä¾‹å¤–å…è¨±ï¼šå¿«é€Ÿä½†é«˜å“è³ªçš„å‹æ…‹
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import pandas as pd
import sqlite3
from datetime import datetime
from n_pattern_detector import NPatternDetector

def scan_with_exception_rules():
    """ä½¿ç”¨ä¾‹å¤–è¦å‰‡é€²è¡Œå…¨å¸‚å ´æƒæ"""
    print("ğŸ¯ Nå­—å›æ’¤æƒæç³»çµ± - ä¾‹å¤–è¦å‰‡ç‰ˆ")
    print("="*60)
    
    # å‡ç´šç‰ˆåƒæ•¸é…ç½®
    detector = NPatternDetector(
        lookback_bars=60,
        use_dynamic_zigzag=True,      # å‹•æ…‹ZigZagé–€æª»
        zigzag_change_pct=0.020,      # å‚™ç”¨2%å›ºå®šé–€æª»
        min_leg_pct=0.06,             # 6%æœ€å°æ³¢æ®µï¼ˆåš´æ ¼ï¼‰
        retr_min=0.20,
        retr_max=0.80,
        c_tolerance=0.00,
        min_bars_ab=3,                # æ¨™æº–ï¼šABæ®µâ‰¥3å¤©
        max_bars_ab=30,               
        min_bars_bc=3,                # æ¨™æº–ï¼šBCæ®µâ‰¥3å¤©
        max_bars_bc=15,               
        max_bars_from_c=12,           # Cé»æ–°é®®åº¦â‰¤12å¤©
        volume_threshold=1.0
    )
    
    print("ğŸ“‹ ç¯©é¸ç­–ç•¥ï¼š")
    print(f"  ğŸ¯ ä¸»è¦æ¨™æº–ï¼šABâ‰¥{detector.min_bars_ab}å¤©, BCâ‰¥{detector.min_bars_bc}å¤©, æ¼²å¹…â‰¥{detector.min_leg_pct:.0%}")
    print(f"  âš¡ ä¾‹å¤–å…è¨±ï¼šå¿«é€Ÿå‹æ…‹ä½†éœ€åš´æ ¼æ¢ä»¶ï¼ˆATRå‹•æ…‹é–€æª» + é‡æ¯”è¦æ±‚ï¼‰")
    print(f"  ğŸ“… æ–°é®®åº¦ï¼šCé»åˆ°ä»Šå¤©â‰¤{detector.max_bars_from_c}å¤©")
    
    # é€£æ¥è³‡æ–™åº«
    conn = sqlite3.connect('data/cleaned/taiwan_stocks_cleaned.db')
    
    stock_query = """
    SELECT DISTINCT stock_id, COUNT(*) as record_count
    FROM daily_prices
    GROUP BY stock_id
    HAVING COUNT(*) >= 60
    ORDER BY stock_id
    """
    
    stock_result = pd.read_sql_query(stock_query, conn)
    all_stocks = stock_result['stock_id'].tolist()
    
    print(f"\nğŸš€ é–‹å§‹æƒæ {len(all_stocks)} æª”è‚¡ç¥¨...")
    print("-" * 60)
    
    signals = []
    standard_signals = []  # ç¬¦åˆæ¨™æº–å‹æ…‹
    exception_signals = []  # ä¾‹å¤–å‹æ…‹
    
    for i, stock_id in enumerate(all_stocks):
        if i % 30 == 0:
            print(f"æƒæé€²åº¦: {i}/{len(all_stocks)} ({i/len(all_stocks)*100:.1f}%) - å·²ç™¼ç¾{len(signals)}å€‹è¨Šè™Ÿ")
        
        try:
            query = """
            SELECT date, open, high, low, close, volume
            FROM daily_prices 
            WHERE stock_id = ?
            ORDER BY date
            """
            df = pd.read_sql_query(query, conn, params=(stock_id,))
            
            if len(df) < 60:
                continue
            
            signal = detector.detect_n_pattern(df, stock_id)
            if signal:
                signals.append(signal)
                
                # åˆ¤æ–·æ˜¯æ¨™æº–å‹æ…‹é‚„æ˜¯ä¾‹å¤–å‹æ…‹
                is_standard = (
                    signal.bars_ab >= detector.min_bars_ab and
                    signal.bars_bc >= detector.min_bars_bc
                )
                
                if is_standard:
                    standard_signals.append(signal)
                    print(f"âœ… {stock_id}: æ¨™æº–å‹æ…‹, è©•åˆ†{signal.score}, AB:{signal.bars_ab}å¤©, BC:{signal.bars_bc}å¤©")
                else:
                    exception_signals.append(signal)
                    print(f"âš¡ {stock_id}: ä¾‹å¤–å‹æ…‹, è©•åˆ†{signal.score}, AB:{signal.bars_ab}å¤©, BC:{signal.bars_bc}å¤©")
        
        except Exception as e:
            continue
    
    conn.close()
    
    # çµæœçµ±è¨ˆ
    print(f"\n" + "="*60)
    print(f"ğŸ‰ æƒæå®Œæˆï¼ç¸½è¨ˆç™¼ç¾ {len(signals)} å€‹Nå­—è¨Šè™Ÿ")
    print(f"  ğŸ“ˆ æ¨™æº–å‹æ…‹ï¼š{len(standard_signals)} å€‹")
    print(f"  âš¡ ä¾‹å¤–å‹æ…‹ï¼š{len(exception_signals)} å€‹")
    
    if not signals:
        print("âŒ æœªç™¼ç¾ç¬¦åˆæ¢ä»¶çš„è¨Šè™Ÿ")
        return
    
    # æŒ‰Cé»æ—¥æœŸæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
    sorted_signals = sorted(signals, key=lambda s: s.C_date, reverse=True)
    
    # é¡¯ç¤ºå‰15å
    print(f"\nğŸ† å‰15å€‹æœ€æ–°è¨Šè™Ÿï¼ˆæŒ‰Cé»æ—¥æœŸæ’åºï¼‰ï¼š")
    print(f"{'è‚¡ç¥¨':<6} {'å‹æ…‹':<4} {'è©•åˆ†':<4} {'Cé»æ—¥æœŸ':<12} {'æ¼²å¹…':<8} {'å›æ’¤':<8} {'ABå¤©':<4} {'BCå¤©':<4} {'æ–°é®®':<4}")
    print("-" * 75)
    
    for signal in sorted_signals[:15]:
        signal_type = "æ¨™æº–" if signal.bars_ab >= 3 and signal.bars_bc >= 3 else "ä¾‹å¤–"
        print(f"{signal.stock_id:<6} {signal_type:<4} {signal.score:<4} {signal.C_date:<12} {signal.rise_pct:.1%}   {signal.retr_pct:.1%}   {signal.bars_ab:<4} {signal.bars_bc:<4} {signal.bars_c_to_signal:<4}")
    
    # åŒ¯å‡ºCSV
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    filename = f"n_pattern_signals_exception_rules_{timestamp}.csv"
    export_to_csv(sorted_signals, filename)
    
    print(f"\nğŸ“ å·²åŒ¯å‡ºCSVï¼š{filename}")
    print(f"ğŸ—‚ï¸  æª”æ¡ˆè·¯å¾‘ï¼š{os.path.abspath(filename)}")

def export_to_csv(signals, filename):
    """åŒ¯å‡ºè¨Šè™Ÿåˆ°CSV"""
    import csv
    
    # è‚¡ç¥¨åç¨±å°æ‡‰
    STOCK_NAMES = {
        '1101': 'å°æ³¥', '1102': 'äºæ³¥', '1108': 'å¹¸ç¦', '1213': 'å¤§é£²', '1215': 'åœèœ‚',
        '1304': 'å°èš', '1305': 'è¯å¤', '1326': 'å°åŒ–', '1440': 'å—ç´¡', '1476': 'å„’é´»',
        '1773': 'å‹ä¸€', '1789': 'ç¥éš†', '2032': 'æ–°é‹¼', '2033': 'ä½³å¤§', '2204': 'ä¸­è¯',
        '2207': 'å’Œæ³°è»Š', '2227': 'è£•æ—¥è»Š', '2301': 'å…‰å¯¶ç§‘', '2303': 'è¯é›»', '2308': 'å°é”é›»',
        '2317': 'é´»æµ·', '2327': 'åœ‹å·¨', '2329': 'è¯ç¢©', '2330': 'å°ç©é›»', '2337': 'æ¼¢å”',
        '2344': 'è¯é‚¦é›»', '2345': 'æ™ºé‚¦', '2351': 'é †å¾·', '2352': 'ä½³ä¸–é”', '2355': 'æ•¬éµ¬',
        '2360': 'è‡´èŒ‚', '2368': 'é‡‘åƒé›»', '2369': 'è±ç”Ÿ', '2374': 'ä½³èƒ½', '2375': 'æ™ºå¯¶',
        '2376': 'æŠ€å˜‰', '2379': 'ç‘æ˜±', '2380': 'è™¹å…‰', '2382': 'å»£é”', '2395': 'ç ”è¯',
        '2408': 'å—äºç§‘', '2409': 'å‹é”', '2454': 'è¯ç™¼ç§‘', '2501': 'åœ‹å»º', '2505': 'åœ‹æš',
        '2506': 'å¤ªè¨­', '2511': 'å¤ªå­', '2515': 'ä¸­å·¥', '2516': 'æ–°å»º', '2520': 'å† å¾·',
        '2524': 'äº¬åŸ', '2809': 'äº¬åŸéŠ€', '2820': 'è¯ç¥¨', '2832': 'å°ç”¢', '2850': 'æ–°ç”¢',
        '2855': 'çµ±ä¸€è­‰', '2867': 'ä¸‰å•†å£½', '3481': 'ç¾¤å‰µ', '4966': 'è­œç‘-KY', '4967': 'åéŠ“',
        '5471': 'æ¾ç¿°', '5483': 'ä¸­ç¾æ™¶', '5525': 'é †å¤©', '6442': 'å…‰è–', '6451': 'è¨ŠèŠ¯-KY',
        '6456': 'GIS-KY', '6488': 'ç’°çƒæ™¶', '6525': 'æ·æ•-KY', '6531': 'æ„›æ™®', '8027': 'éˆ¦æ˜‡'
    }
    
    def get_stock_name(stock_id):
        return STOCK_NAMES.get(stock_id, stock_id)
    
    # æº–å‚™CSVè³‡æ–™
    csv_data = []
    
    for signal in signals:
        signal_type = "æ¨™æº–å‹æ…‹" if signal.bars_ab >= 3 and signal.bars_bc >= 3 else "ä¾‹å¤–å‹æ…‹"
        
        # è¨ˆç®—æ™‚é–“é–“è·
        from datetime import datetime
        A_dt = datetime.strptime(signal.A_date, '%Y-%m-%d')
        B_dt = datetime.strptime(signal.B_date, '%Y-%m-%d')
        C_dt = datetime.strptime(signal.C_date, '%Y-%m-%d')
        signal_dt = datetime.strptime(signal.signal_date, '%Y-%m-%d')
        
        days_AB = (B_dt - A_dt).days
        days_BC = (C_dt - B_dt).days
        days_C_to_signal = (signal_dt - C_dt).days
        
        row = [
            signal.stock_id,
            get_stock_name(signal.stock_id),
            signal_type,
            signal.score,
            signal.A_date, signal.A_price,
            signal.B_date, signal.B_price,
            signal.C_date, signal.C_price,
            signal.signal_date,
            f"{signal.rise_pct*100:.2f}%",
            f"{signal.retr_pct*100:.1f}%",
            days_AB, days_BC, days_C_to_signal,
            signal.rsi14, signal.ema5, signal.ema20, signal.volume_ratio,
            "æ˜¯" if signal.trigger_break_yesterday_high else "å¦",
            "æ˜¯" if signal.trigger_ema5_volume else "å¦",
            "æ˜¯" if signal.trigger_rsi_strong else "å¦",
            signal.score_breakdown.get('retracement', 0),
            signal.score_breakdown.get('volume', 0),
            signal.score_breakdown.get('early_entry', 0),
            signal.score_breakdown.get('moving_average', 0),
            signal.score_breakdown.get('health', 0),
        ]
        csv_data.append(row)
    
    # å¯«å…¥CSV
    headers = [
        'è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'å‹æ…‹é¡å‹', 'ç¶œåˆè©•åˆ†',
        'Aé»æ—¥æœŸ', 'Aé»åƒ¹æ ¼', 'Bé»æ—¥æœŸ', 'Bé»åƒ¹æ ¼', 'Cé»æ—¥æœŸ', 'Cé»åƒ¹æ ¼', 'è¨Šè™Ÿæ—¥æœŸ',
        'ä¸Šæ¼²å¹…åº¦', 'å›æ’¤æ¯”ä¾‹', 'ABæ®µå¤©æ•¸', 'BCæ®µå¤©æ•¸', 'Cåˆ°è¨Šè™Ÿå¤©æ•¸',
        'RSI14', 'EMA5', 'EMA20', 'é‡æ¯”',
        'çªç ´æ˜¨é«˜', 'EMA5é‡å¢', 'RSIå¼·å‹¢',
        'å›æ’¤è©•åˆ†', 'é‡èƒ½è©•åˆ†', 'æ—©é€²è©•åˆ†', 'å‡ç·šè©•åˆ†', 'å¥åº·è©•åˆ†'
    ]
    
    with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(headers)
        writer.writerows(csv_data)

if __name__ == "__main__":
    scan_with_exception_rules()